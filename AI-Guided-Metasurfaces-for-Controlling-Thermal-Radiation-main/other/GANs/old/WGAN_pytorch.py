# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CwKsgWL31m-4xWszDvPbOT_seOVRhTRv
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torchvision.transforms import InterpolationMode
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
import os
import time

# --- 0. Setup and Device Configuration ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# --- 1. Hyperparameters ---
DATAROOT = "/home/fu/travis/Projects/Metasurfaces/AI-Guided-Metasurfaces-for-Controlling-Thermal-Radiation/Data/Data_Generated_Images/"  # e.g., "/content/drive/MyDrive/MetaSurfaces_Final1/Data"
IMAGE_SIZE = 128 # If this is changed, need to change how many Conv2D Layers there are in the generator to make it match. If we can, jumping to 256 should have significant increase in performance.
CHANNELS = 1  # Grayscale
BATCH_SIZE = 64
WORKERS = 2 # Number of workers for dataloader
NOISE_DIM = 100
NGF = 64  # Number of generator features
NDF = 64  # Number of critic features
NUM_EPOCHS = 10000
N_CRITIC = 5      # Number of critic updates per generator update
GP_WEIGHT = 10.0  # Gradient penalty weight

# Learning Rate and Optimizer Adjustments
INITIAL_LR_G = 0.0002 # Initial LR for cosine annealing
INITIAL_LR_C = 0.0002 # Initial LR for cosine annealing
# T_MAX for CosineAnnealingLR will be total iterations (num_epochs * num_batches_per_epoch)
BETA1_ADAM = 0.0 # WGAN-GP typical beta1
BETA2_ADAM = 0.9 # WGAN-GP typical beta2

# Optional: Generator Gradient Clipping
CLIP_NORM_G = None # Set to a value like 1.0 or 5.0 to enable, or None to disable

# Output Directories
OUTPUT_DIR = "/home/fu/travis/Projects/Metasurfaces/AI-Guided-Metasurfaces-for-Controlling-Thermal-Radiation/python/GANs/wgan_gp_pytorch_output"
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(os.path.join(OUTPUT_DIR, "images"), exist_ok=True)
os.makedirs(os.path.join(OUTPUT_DIR, "checkpoints"), exist_ok=True)

# --- Weight Initializers (DCGAN-style) ---
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1: # Covers Conv2d and ConvTranspose2d
        nn.init.normal_(m.weight.data, 0.0, 0.02)
        if m.bias is not None: # Initialize bias if it exists (though often use_bias=False before BN)
            nn.init.constant_(m.bias.data, 0)
    elif classname.find('BatchNorm2d') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02) # Gamma
        nn.init.constant_(m.bias.data, 0)        # Beta
    elif classname.find('Linear') != -1: # For Dense layers
        nn.init.normal_(m.weight.data, 0.0, 0.02)
        if m.bias is not None:
            nn.init.constant_(m.bias.data, 0)


# --- 2. Data Loading and Preprocessing ---
try:
    dataset = dset.ImageFolder(root=DATAROOT,
                               transform=transforms.Compose([
                                   transforms.Grayscale(num_output_channels=CHANNELS),
                                   transforms.Resize(IMAGE_SIZE, interpolation=InterpolationMode.BICUBIC),
                                   transforms.CenterCrop(IMAGE_SIZE),
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5,) * CHANNELS, (0.5,) * CHANNELS) # Normalize to [-1, 1]
                               ]))
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,
                                             shuffle=True, num_workers=WORKERS, drop_last=True, pin_memory=True)

    num_batches_per_epoch = len(dataloader)
    print(f"Dataset loaded. Number of batches per epoch: {num_batches_per_epoch}")
    DECAY_STEPS_TOTAL = num_batches_per_epoch * NUM_EPOCHS # T_max for CosineAnnealingLR
    print(f"Total decay steps (iterations) for LR scheduler: {DECAY_STEPS_TOTAL}")


    # Plot some training images
    real_batch_sample = next(iter(dataloader))
    plt.figure(figsize=(8,8))
    plt.axis("off")
    plt.title(f"Sample Training Images (Resized to {IMAGE_SIZE}x{IMAGE_SIZE})")
    plt.imshow(np.transpose(vutils.make_grid(real_batch_sample[0].to(device)[:min(16, BATCH_SIZE)], padding=2, normalize=True).cpu(),(1,2,0)))
    plt.savefig(os.path.join(OUTPUT_DIR, "sample_training_images_wgan_gp_pytorch.png"))
    plt.close() # Ensure the figure is closed after saving

except Exception as e:
    print(f"An error occurred during data loading: {e}")
    raise e

# --- 3. Model Definitions with Initializers ---
# Generator
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d(NOISE_DIM, NGF * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(NGF * 8),
            nn.ReLU(True),
            # state size. (NGF*8) x 4 x 4
            nn.ConvTranspose2d(NGF * 8, NGF * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(NGF * 4),
            nn.ReLU(True),
            # state size. (NGF*4) x 8 x 8
            nn.ConvTranspose2d(NGF * 4, NGF * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(NGF * 2),
            nn.ReLU(True),
            # state size. (NGF*2) x 16 x 16
            nn.ConvTranspose2d(NGF * 2, NGF, 4, 2, 1, bias=False),
            nn.BatchNorm2d(NGF),
            nn.ReLU(True),
            # state size. (NGF) x 32 x 32
            nn.ConvTranspose2d(NGF, CHANNELS, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (CHANNELS) x 64 x 64
        )
    def forward(self, input_noise):
        return self.main(input_noise)

# Critic (No Batch Normalization, No Sigmoid)
class Critic(nn.Module):
    def __init__(self):
        super(Critic, self).__init__()
        self.main = nn.Sequential(
            # input is (CHANNELS) x 64 x 64
            nn.Conv2d(CHANNELS, NDF, 4, 2, 1, bias=False), # Kernel 4, Stride 2, Pad 1 is common too
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (NDF) x 32 x 32
            nn.Conv2d(NDF, NDF * 2, 4, 2, 1, bias=False),
            # Optional: nn.LayerNorm([NDF * 2, 16, 16]) # If using LayerNorm
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (NDF*2) x 16 x 16
            nn.Conv2d(NDF * 2, NDF * 4, 4, 2, 1, bias=False),
            # Optional: nn.LayerNorm([NDF * 4, 8, 8])
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (NDF*4) x 8 x 8
            nn.Conv2d(NDF * 4, NDF * 8, 4, 2, 1, bias=False),
            # Optional: nn.LayerNorm([NDF * 8, 4, 4])
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (NDF*8) x 4 x 4
            nn.Conv2d(NDF * 8, 1, 4, 1, 0, bias=False) # Output raw score
            # state size. 1 x 1 x 1
        )
    def forward(self, input_image):
        return self.main(input_image).view(-1, 1).squeeze(1) # Output a scalar score per image

generator = Generator().to(device)
critic = Critic().to(device)

generator.apply(weights_init)
critic.apply(weights_init)

# --- 4. Optimizers with LR Scheduling ---
optimizer_G = optim.Adam(generator.parameters(), lr=INITIAL_LR_G, betas=(BETA1_ADAM, BETA2_ADAM))
optimizer_C = optim.Adam(critic.parameters(), lr=INITIAL_LR_C, betas=(BETA1_ADAM, BETA2_ADAM))

# Learning Rate Schedulers
scheduler_G = CosineAnnealingLR(optimizer_G, T_max=DECAY_STEPS_TOTAL, eta_min=INITIAL_LR_G*0.001) # End LR at 0.1%
scheduler_C = CosineAnnealingLR(optimizer_C, T_max=DECAY_STEPS_TOTAL, eta_min=INITIAL_LR_C*0.001)

# Gradient Penalty function
def compute_gradient_penalty(critic_net, real_samples, fake_samples, current_batch_size_gp):
    alpha = torch.rand(current_batch_size_gp, 1, 1, 1, device=device) # Uniformly sample
    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)
    c_interpolates = critic_net(interpolates)
    gradients = torch.autograd.grad(
        outputs=c_interpolates,
        inputs=interpolates,
        grad_outputs=torch.ones_like(c_interpolates, device=device), # Using ones_like for scalar output
        create_graph=True,
        retain_graph=True,
        only_inputs=True,
    )[0]
    gradients = gradients.view(gradients.size(0), -1)  # Flatten
    gradient_penalty_val = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
    return gradient_penalty_val

# --- Checkpoints ---
checkpoint_dir = os.path.join(OUTPUT_DIR, 'checkpoints')
# For fixed noise generation
fixed_noise = torch.randn(min(64, BATCH_SIZE), NOISE_DIM, 1, 1, device=device)


# --- 5. Training Loop ---
img_list_pytorch = []
G_losses_pytorch = []
C_losses_pytorch = []
iters = 0
print("Starting WGAN-GP Training with PyTorch...")

for epoch in range(NUM_EPOCHS):
    start_time_epoch = time.time()
    for i, data in enumerate(dataloader, 0):
        real_images = data[0].to(device)
        current_batch_s = real_images.size(0)

        # ---------------------
        #  Train Critic
        # ---------------------
        for _ in range(N_CRITIC):
            optimizer_C.zero_grad()
            noise = torch.randn(current_batch_s, NOISE_DIM, 1, 1, device=device)
            fake_images = generator(noise).detach() # Detach to avoid training G on C's pass

            # Get scores for real and fake images
            real_scores = critic(real_images)
            fake_scores_d = critic(fake_images) # For D_G_z1 logging

            # Gradient penalty
            gradient_penalty_val = compute_gradient_penalty(critic, real_images.data, fake_images.data, current_batch_s)

            # Critic loss
            loss_c = fake_scores_d.mean() - real_scores.mean() + GP_WEIGHT * gradient_penalty_val
            loss_c.backward()
            optimizer_C.step()

        # -----------------
        #  Train Generator
        # -----------------
        optimizer_G.zero_grad()
        # Generate a new batch of fake images
        gen_noise = torch.randn(current_batch_s, NOISE_DIM, 1, 1, device=device)
        gen_fake_images = generator(gen_noise)
        fake_scores_g = critic(gen_fake_images) # For D_G_z2 logging and G loss

        # Generator loss
        loss_g = -fake_scores_g.mean()
        loss_g.backward()

        # Optional: Gradient Clipping for Generator
        if CLIP_NORM_G is not None:
            torch.nn.utils.clip_grad_norm_(generator.parameters(), CLIP_NORM_G)
        optimizer_G.step()

        # Step the schedulers after each optimizer step (i.e., per iteration/batch)
        scheduler_G.step()
        scheduler_C.step()

        # Output training stats
        if i % 50 == 0:
            c_x_val = real_scores.mean().item()
            c_g_z1_val = fake_scores_d.mean().item() # From last critic update on G's fakes
            c_g_z2_val = fake_scores_g.mean().item() # From G's update on its fakes
            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{i}/{num_batches_per_epoch}], Loss_C: {loss_c.item():.4f}, Loss_G: {loss_g.item():.4f}, '
                  f'C(x): {c_x_val:.4f}, C(G(z)): {c_g_z1_val:.4f} / {c_g_z2_val:.4f}, '
                  f'LR_G: {optimizer_G.param_groups[0]["lr"]:.2e}, LR_C: {optimizer_C.param_groups[0]["lr"]:.2e}')

        G_losses_pytorch.append(loss_g.item())
        C_losses_pytorch.append(loss_c.item())

        if (iters % 200 == 0) or ((epoch == NUM_EPOCHS-1) and (i == num_batches_per_epoch-1)):
            with torch.no_grad():
                fake_display = generator(fixed_noise).detach().cpu()
            img_list_pytorch.append(vutils.make_grid(fake_display, padding=2, normalize=True))
            vutils.save_image(fake_display, f"{OUTPUT_DIR}/images/epoch_{epoch+1}_iter_{iters}.png", normalize=True)
        iters += 1

    # Save checkpoint
    if (epoch + 1) % 10 == 0 or epoch == NUM_EPOCHS - 1:
        torch.save({
            'epoch': epoch + 1,
            'generator_state_dict': generator.state_dict(),
            'critic_state_dict': critic.state_dict(),
            'optimizer_G_state_dict': optimizer_G.state_dict(),
            'optimizer_C_state_dict': optimizer_C.state_dict(),
            'scheduler_G_state_dict': scheduler_G.state_dict(),
            'scheduler_C_state_dict': scheduler_C.state_dict(),
            'G_losses': G_losses_pytorch,
            'C_losses': C_losses_pytorch,
            'fixed_noise': fixed_noise,
            'iters': iters,
        }, f'{checkpoint_dir}/wgan_gp_ckpt_epoch_{epoch+1}.pth')
        print(f"Saved checkpoint for epoch {epoch+1}")

    print(f'Time for epoch {epoch + 1} is {time.time()-start_time_epoch:.2f} sec')

print("Training Finished.")

# --- Plotting Results ---
plt.figure(figsize=(12,6))
plt.subplot(1, 2, 1)
plt.title("Generator and Critic Loss (PyTorch WGAN-GP)")
plt.plot(C_losses_pytorch,label="Critic Loss (C)")
plt.plot(G_losses_pytorch,label="Generator Loss (G)")
plt.xlabel("Iterations (Batches)")
plt.ylabel("Loss")
plt.legend()

plt.subplot(1, 2, 2)
# A more accurate way would be to log LR per iteration
logged_lr_g = []
temp_optimizer = optim.Adam(generator.parameters(), lr=INITIAL_LR_G) # Dummy for scheduler
temp_scheduler = CosineAnnealingLR(temp_optimizer, T_max=DECAY_STEPS_TOTAL, eta_min=INITIAL_LR_G*0.001)
for _ in range(DECAY_STEPS_TOTAL):
    logged_lr_g.append(temp_scheduler.get_last_lr()[0])
    temp_scheduler.step()

plt.plot(np.arange(len(logged_lr_g)), logged_lr_g, label="Scheduled LR (G/C)")
plt.title("Learning Rate Schedule (Cosine Annealing)")
plt.xlabel("Iterations (Batches)")
plt.ylabel("Learning Rate")
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "loss_and_lr_curve_wgan_gp_pytorch.png"))
plt.close() # Ensure the figure is closed after saving

print(f"Outputs saved in directory: {OUTPUT_DIR}")